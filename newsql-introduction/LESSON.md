# メモと学び

TiDBはMySQLに寄せて作られている

mysqlクライアントで接続可能

## TiDBの機能概要

- オートスケールしない。ノード数はユーザが決める
- 外部キーはサポートしている。サポートしていないNewSQLもある
- レプリカノードがない
- 分離レベルはSnapshot Isolation

## TiDBのアーキテクチャ

- TiDB: SQLを解釈、実行計画を作成するコンピューティングノード
- TiKV: 分散KVSストレージノード。
  - 内部的にRocksDBを使用し、Raftでリーダーを管理
- PD: 各ノードの配置状況やクラスタの状況を管理するノード
  - どのTiKVノードにアクセスすればよいか教える+タイムスタンプを発行する役割を担う
  - etcdでリーダー管理。
- TiProxy: TiDBを複数台冗長化している場合のロードバランサ
- TiFlash: 列指向フォーマットキャッシュ？DWH向け機能らしいのでおそらくそう


クエリ実行の流れ
1. TiDBノードでSQL解析・最適化
2. PDノードの情報をもとにやりとりするTiKVノードを決定
3. TiKVへ検索
4. 結果集約・生成


TiKVに格納されるデータは3重冗長化される

TiKVではデータの保存単位としてリージョンというデータ塊を管理する。複数のレコードをPKの一定の範囲で区切ったもの(シャードみたいなもの)。

TiDBはリージョン単位でTiKVにアクセスする

リージョンごとに読み書きを担当するTiKVサーバ(リーダー)が決まっている。

レプリケーションの遅延を無くしデータ一貫性を保つため、デフォルトではリーダーからだけ読み書きする。PDがTiDBへリーダー情報を伝達する。

リージョンフォロワーからも読み込みできるオプションはある


トランザクションの書き込みには2相コミットを採用

TiKV内でのリーダーからフォロワーへのデータ複製にはRaftを使用している

コピー最中に障害が発生したり、ネットワーク不具合などでコピーに問題が発生した場合でもデータの整合性を保つための合意アルゴリズム

PDはデータの更新時に、書き込む対象のTiKVノード(リーダー)を教える役割とタイムスタンプを発行する役割の2つを担当する

更新されるレコードに対して更新時のTSO(Timestamp Oracle)を付与し、レコードの複数のバージョンを保存する。これによってSnapshot isolationを実現する

### SQL -> KVS内部変換

行ごとにKVSに保存する。


`Table ID(テーブルID) + Row Key(行ID)`の値をキー、その他のカラムの値をバリューにする

このキーの一定範囲ごとにリージョンに振り分ける

### Compilerによる実行計画作成後の流れ

Executorによる実際のクエリ実行に移る

- トランザクションモジュールへと処理が移る
  - TSO(Timestamp Oracle) をPDから取得
  - 2相コミットやロックの管理
- クエリの内容に応じてシンプルなKVS API **KV** と複雑な処理を行うAPI **DistSQL** を使い分ける
  - KV: 単一のTiKVへのアクセスを担当するモジュール
  - DistSQL: TiDBとTiKVにあるCoprocessorとの間で、TiKVでクエリを並列実行できるよう分散したり一部タスクをTiKVに委任したりと効率化を担う
- KV, DistSQLからTiKVクライアントへ処理が流れる\る

### RocksDBの構造

LSMツリーベースのストレージエンジン

データ書き込み時には以下の流れを踏む。Immutableなデータ構造なので書き込みが速い

- WALにキーバリューペアを挿入
- メモリ上のMemTable(SkipList)に書き込み
  - キー順にソートされたデータを保持する書き込みバッファ
- データをソート&マージしてディスクに追記(SST=Sorted String Tableファイルへ変換)

更新・削除時には削除フラグを適用してMemTableに書き込みし、SSTをコンパクションする際に削除フラグを実際に適用してデータを削除する

データ読み込み時には以下の流れを踏む。

- Block Cacheをチェック
  - LRUキャッシュ
- MemTableを検索
- SSTを逆順に検索(ブルームフィルタを使って高速化)

カラムファミリー機能をサポートしており、複数のカラムファミリーにまたがる書き込み処理を一つのトランザクションとして実行できる

MemTableやSSTはカラムファミリーごとに独立して管理される。WALはすべてのカラムファミリーで共通であり、全てのカラムファミリーでMemTableのフラッシュが完了した後に削除される

- Lock CF(Column Family): トランザクション制御に必要なロック情報を保存するCF。Percolatorベースの分散トランザクションモデルを採用しており、そのために行ロックが必要。2相コミットする
- Write CF: MVCCに必要なメタデータを保存するCF。
- Default CF: ユーザーが書き込んだ実際のデータを格納するCF。Write CFに保存しきれなかったデータ実態が255バイトを超えた際に保存。

以上3種類を活用してSnapshot Isolationを実現

### 分散トランザクションの仕組み(悲観的)

TiDBノード

- BEGIN
  - PDからstart_ts(トランザクション開始時刻)を取得
- SELECTやINSERT
  - start_tsを基にキーバリューデータを生成、Lock CFにロック情報を格納
- COMMIT
  - PDからcommit_ts(コミット時刻)を取得
  - Write CFにstart_tsとcommit_tsを組み合わせたデータを保存してトランザクションを確定

ロックが複数のノードに渡って行われる場合、最初に取得したロックをプライマリロックとみなし、それ以外のロックはプライマリロックへのポインタを保持する

Prewriteタイミングでデータの保存とロックの取得を行う -> 全ノードでPrewriteが成功してからCommitフェーズに進むことで2相コミットを実現している


### Raftによるノード間の一貫性維持

Raftの基本理念: すべてのノードが同一のステートマシンとして動作する。同じ順序で操作を実行し、最終的に全体として整合性のとれた状態に到達させる

各操作が「ログエントリ」として記録され、ログエントリごとに一意な識別子が割り当てられる

TiKVではリージョンごとに独自のRaftグループとして運用する

- リーダー選出の動き
  - 各ノードがフォロワーとして動作し、リーダーからの定期的なハートビートを受信
  - リーダーからのハートビートが一定時間受け取れなくなると、一定期間(選挙タイムアウト)後に自身をリーダーの候補者に昇格する
    - 選挙タイムアウトはランダムな値に設定され、複数の候補者が乱立するのを避ける
  - 各ノードは昇格とともに現在の任期番号(term)を更新する。これは過去の選挙と新たな選挙の開始を識別するための番号
  - 候補者ノードはまず自らに投票し、他のノードに対して投票要求を送信
    - 投票要求には候補者の任期番号と最新のログ情報が含まれる
  - フォロワーは自身が持つログの整合性と照らして投票要求の整合性を判断、投票
  - 過半数の票を獲得したノードはリーダーに昇格。全ノードに自身がリーダーであることのハートビートを通知
- ログレプリケーションの動き
  - Proposeフェーズ
    - TiDBノードのデータ操作要求が対象リージョンのリーダーに送信される
  - Appendフェーズ
    - リーダーはログエントリーを自身のRaft Logに追記する
  - Replicateフェーズ
    - 各フォロワーに同一のログエントリーを送信する
  - Commitフェーズ
    - 過半数のAcckを受信するとそのエントリーはCommitとして確定される
  - Applyフェーズ
    - リーダーが確定した内容をRocksDBのKV層に反映させる

## TiDBの各種機能

### バックアップ

```
BACKUP DATABASE <database name> to 'local://<保存ディレクトリへの絶対パス>'
```

```
RESTORE DATABASE * FROM 'local://<保存ディレクトリへの絶対パス>'
```

### ノード冗長性

- TiDBサーバはステートレスなので、1台停止してもTiProxy経由で再接続でき新しいサーバを起動すれば状態を復元できる
  - 停止したTiDBサーバ上で実行中だったトランザクションはロールバックされる
- TiKVサーバは相互にハートビートを送っており、TiKVノードがダウンした際にフォロワーがRaftによりリーダーに昇格する
  - TiDBノードは新しいリーダーにリクエストをリトライする
  - 過半数が止まってしまった場合はネットワーク分断と区別がつかないため自動復旧はできず、どのデータを正とするかは人間の判断が必要になる
  - 手動復旧する際はPDのクラスター情報を直接書き換える(停止したノードをクラスタから除外、新しいTiKVノードを加えてスケールアウト)
- PDサーバは基本的に3台構成で、全ての処理をリーダーが担当。etcdベースで作られている。etcdもRaftベースなのでTiKVと同様の冗長性
  - 手動復旧する際はリージョン情報とTSOの最大値が必要になる
  - 一度データを削除し、新規PDサーバにTiKVに保存されているリージョン情報と過去のTSOよりも十分に大きい値を与えれば手動復旧は可能

## コマンドログ

TiDBサーバのポート番号とプロセスIDの対応関係を調べる

```sql
select ddl_id, ip, port from information_schema.tidb_servers_info;
```

リージョンごとのregion_idを調べる

```sql
select region_id, start_key, end_key,table_name, db_name from information_schema.tikv_regi
on_status where table_name = 'Books';
```

```
+-----------+--------------------------------------+--------------------------------------+------------+---------+
| region_id | start_key                            | end_key                              | table_name | db_name |
+-----------+--------------------------------------+--------------------------------------+------------+---------+
|       276 | 7480000000000000FF7000000000000000F8 | 7480000000000000FF7200000000000000F8 | Books      | library |
+-----------+--------------------------------------+--------------------------------------+------------+---------+
1 row in set (0.01 sec)
```

リージョンIDごとにリーダーのストアIDを調べる

```
select * from information_schema.tikv_region_peers where is_leader = 1 order by region_id;
```

リージョンID276のリーダーのストアIDは3と判明

ストアIDとノードの対応関係を調べる

```
select * from information_schema.tikv_store_status;
```

リージョンIDとポート番号の関係を一発で調べる便利コマンド

```sql
use information_schema;
select region_id, store_id, address from tikv_region_status natural join tikv_region_peers
 natural join tikv_store_status where is_leader = 1 and table_name = 'Books';
```

ストアID3に対応するノードは127.0.0.1:20160と判明

`lsof -i:20161 | grep LISTEN` でプロセス51726がポート20160を使っていると判明

プロセス51726を停止しようとすると、tiupでは検証されてエラー
```
tiup playground scale-in --pid 51726
```
```
no endpoint available, the last err was: error requesting http://127.0.0.1:2384/pd/api/v1/store/3, response: "[PD:core:ErrStoresNotEnough]can not remove store 3 since the number of up stores would be 2 while need 3"
```
強制killする


PDサーバの状態を調べる
```
tiup ctl:v8.5.4 pd member show
```
